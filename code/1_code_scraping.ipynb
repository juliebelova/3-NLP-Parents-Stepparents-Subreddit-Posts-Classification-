{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Web APIs & NLP\n",
    "## Notebook I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Julie Vovchenko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Content:\n",
    "- [Scrapping](#Scrapping)\n",
    "    -  [Defining Subreddits](#Defining-Subreddits)  \n",
    "    -  [Scrapping Subreddits](#Scrapping-Subreddits) \n",
    "    -  [Saving Raw Data](#Saving-Raw-Data) \n",
    "\n",
    "### Dataset\n",
    "\n",
    "- [Scrapped Raw Data from Both Subreddits](../data/both_scraped_subreddits.csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries: \n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time \n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using two subreddits for the analysis: \n",
    "# 'Parenting' and 'stepparents'\n",
    "subreddit_1='Parenting'\n",
    "subreddit_2='stepparents'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping Subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function does scrapping from reddit.com with a given subreddit\n",
    "\n",
    "# query_pushshift function take the following parameters: \n",
    "# subreddit - name of the subreddit from which we collect data\n",
    "# Default Parameters: \n",
    "# skip: how many days you want your time go back (skip=30)\n",
    "# times: how many time to collect api query into this list (times=5)\n",
    "# subfields: rows of data that we need to collect\n",
    "# comfields: other columns name for scrapping\n",
    "\n",
    "\n",
    "def query_pushshift(subreddit, kind='submission', skip=30, times=5, \n",
    "                    subfield = ['title', 'selftext', \n",
    "                                'subreddit', 'created_utc', \n",
    "                                'author', 'num_comments', \n",
    "                                'score', 'is_self'],\n",
    "                    comfields = ['body', 'score', 'created_utc']):\n",
    "    stem = \"https://api.pushshift.io/reddit/search/{}/?subreddit={}&size=500\".format(kind, subreddit)\n",
    "    \n",
    "    # to store data we get from website\n",
    "    mylist = [] #will have a list of 5 times posts from subs\n",
    "    \n",
    "    #append the results to the empty list above\n",
    "    for x in range(1, times + 1): #should run 5 time (6(times+1), but it starts from 1)\n",
    "        \n",
    "        URL = \"{}&after={}d\".format(stem, skip * x) #URL stem, 30/60/90 days\n",
    "        print(URL)\n",
    "        \n",
    "        #scrapping\n",
    "        response = requests.get(URL)\n",
    "        #checking if the response was successfull\n",
    "        assert response.status_code == 200\n",
    "        \n",
    "        mine = response.json()['data'] #'data' list\n",
    "        df = pd.DataFrame.from_dict(mine)\n",
    "        mylist.append(df)\n",
    "        time.sleep(2)\n",
    "        \n",
    "    #creates of df object full that will be 5 subreaded data  \n",
    "    full = pd.concat(mylist, sort=False)\n",
    "    \n",
    "    \n",
    "    if kind == \"submission\":\n",
    "        full = full[subfield]\n",
    "        #delete duplicates that might occur during scrapping\n",
    "        full = full.drop_duplicates() \n",
    "        full = full.loc[full['is_self'] == True] \n",
    "        \n",
    "    def get_date(created):\n",
    "        return dt.date.fromtimestamp(created)\n",
    "    \n",
    "    \n",
    "    full['timestamp'] = full[\"created_utc\"].apply(get_date)\n",
    "   \n",
    "    print(full.shape)\n",
    "    return full "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.pushshift.io/reddit/search/submission/?subreddit=Parenting&size=500&after=30d\n",
      "https://api.pushshift.io/reddit/search/submission/?subreddit=Parenting&size=500&after=60d\n",
      "https://api.pushshift.io/reddit/search/submission/?subreddit=Parenting&size=500&after=90d\n",
      "https://api.pushshift.io/reddit/search/submission/?subreddit=Parenting&size=500&after=120d\n",
      "https://api.pushshift.io/reddit/search/submission/?subreddit=Parenting&size=500&after=150d\n",
      "(2500, 9)\n"
     ]
    }
   ],
   "source": [
    "# Running the function query_pushshift that scrapes all data from \n",
    "# subreddit_1, which is 'Parenting'\n",
    "sub_1_query = query_pushshift(subreddit_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the size of the dataframe for scraping \n",
    "# subreddit_1, which is 'Parenting'\n",
    "sub_1_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.pushshift.io/reddit/search/submission/?subreddit=stepparents&size=500&after=30d\n",
      "https://api.pushshift.io/reddit/search/submission/?subreddit=stepparents&size=500&after=60d\n",
      "https://api.pushshift.io/reddit/search/submission/?subreddit=stepparents&size=500&after=90d\n",
      "https://api.pushshift.io/reddit/search/submission/?subreddit=stepparents&size=500&after=120d\n",
      "https://api.pushshift.io/reddit/search/submission/?subreddit=stepparents&size=500&after=150d\n",
      "(2494, 9)\n"
     ]
    }
   ],
   "source": [
    "# Running the function query_pushshift that scrapes all data from \n",
    "# subreddit_2, which is 'stepparents'\n",
    "sub_2_query = query_pushshift(subreddit_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2494, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the size of the dataframe for scraping \n",
    "# subreddit_2, which is 'stepparents'\n",
    "sub_2_query.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**  \n",
    "Since we have collected about 2,500 posts from each subreddits, total of almost 5,000 posts, we believe it is sufficient enough data to establish proper predictions and to determine specific words that would indicate the group posting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating both data scrapping into one large dataframe\n",
    "both_dataframes = [sub_1_query, sub_2_query]\n",
    "\n",
    "df = pd.concat(both_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two month old sleeping 8-9 hours at a time.</td>\n",
       "      <td>My daughter is two months old today. Normally ...</td>\n",
       "      <td>Parenting</td>\n",
       "      <td>1577553731</td>\n",
       "      <td>shiteinmemooth</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Living room takeovers</td>\n",
       "      <td>Son spends all his waking hours watching YouTu...</td>\n",
       "      <td>Parenting</td>\n",
       "      <td>1577553829</td>\n",
       "      <td>Rach_InOz</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I freaking hate the baby stage.</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>Parenting</td>\n",
       "      <td>1577553878</td>\n",
       "      <td>HokieGirl07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-12-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "0  Two month old sleeping 8-9 hours at a time.   \n",
       "1                        Living room takeovers   \n",
       "2              I freaking hate the baby stage.   \n",
       "\n",
       "                                            selftext  subreddit  created_utc  \\\n",
       "0  My daughter is two months old today. Normally ...  Parenting   1577553731   \n",
       "1  Son spends all his waking hours watching YouTu...  Parenting   1577553829   \n",
       "2                                          [removed]  Parenting   1577553878   \n",
       "\n",
       "           author  num_comments  score  is_self   timestamp  \n",
       "0  shiteinmemooth             7      1     True  2019-12-28  \n",
       "1       Rach_InOz            11      1     True  2019-12-28  \n",
       "2     HokieGirl07             1      1     True  2019-12-28  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing top rows of the raw dataframe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4994, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the size of the whole dataframe with both subreddits\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving raw data into one file \n",
    "# will do all the exploratory data analysis and modeling in next notebooks\n",
    "df.to_csv('../data/both_scraped_subreddits.csv', index = None);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
